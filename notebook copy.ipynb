{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"execution": {"iopub.execute_input": "2023-09-10T03:44:13.569256Z", "iopub.status.busy": "2023-09-10T03:44:13.566639Z", "iopub.status.idle": "2023-09-10T03:44:20.580734Z", "shell.execute_reply": "2023-09-10T03:44:20.571659Z"}}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "import string\n", "import random\n", "import time\n", "import math\n", "import matplotlib.pyplot as plt\n", "import matplotlib.ticker as ticker\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {"execution": {"iopub.execute_input": "2023-09-10T03:44:20.608316Z", "iopub.status.busy": "2023-09-10T03:44:20.605203Z", "iopub.status.idle": "2023-09-10T03:44:20.652333Z", "shell.execute_reply": "2023-09-10T03:44:20.647435Z"}}, "outputs": [], "source": ["lorem_ipsum = \"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis quis eros tincidunt, dapibus mi in, tincidunt sapien. Vivamus massa nunc, finibus condimentum mattis id, iaculis a nibh. Aenean quis convallis diam. In hac habitasse platea dictumst. Quisque lacinia convallis.\"\n", "\n", "all_characters = string.printable\n", "n_characters = len(all_characters)\n", "\n", "# Functions to convert characters to and from tensors\n", "\n", "def char_to_tensor(char):\n", "    tensor = torch.zeros(1, n_characters)\n", "    tensor[0][all_characters.index(char)] = 1\n", "    return tensor\n", "\n", "def line_to_tensor(line):\n", "    tensor = torch.zeros(len(line), 1, n_characters)\n", "    for idx, char in enumerate(line):\n", "        tensor[idx][0][all_characters.index(char)] = 1\n", "    return tensor\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {"execution": {"iopub.execute_input": "2023-09-10T03:44:20.671115Z", "iopub.status.busy": "2023-09-10T03:44:20.668602Z", "iopub.status.idle": "2023-09-10T03:44:20.713399Z", "shell.execute_reply": "2023-09-10T03:44:20.709214Z"}}, "outputs": [], "source": ["class RNN(nn.Module):\n", "    def __init__(self, input_size, hidden_size, output_size):\n", "        super(RNN, self).__init__()\n", "        self.hidden_size = hidden_size\n", "\n", "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n", "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n", "        self.o2o = nn.Linear(hidden_size + output_size, output_size)\n", "        self.dropout = nn.Dropout(0.1)\n", "        self.softmax = nn.LogSoftmax(dim=1)\n", "\n", "    def forward(self, input, hidden):\n", "        input_combined = torch.cat((input, hidden), 1)\n", "        hidden = self.i2h(input_combined)\n", "        output = self.i2o(input_combined)\n", "        output_combined = torch.cat((hidden, output), 1)\n", "        output = self.o2o(output_combined)\n", "        output = self.dropout(output)\n", "        output = self.softmax(output)\n", "        return output, hidden\n", "\n", "    def initHidden(self):\n", "        return torch.zeros(1, self.hidden_size)\n"]}, {"cell_type": "code", "execution_count": 4, "metadata": {"execution": {"iopub.execute_input": "2023-09-10T03:44:20.730478Z", "iopub.status.busy": "2023-09-10T03:44:20.728734Z", "iopub.status.idle": "2023-09-10T03:44:22.460949Z", "shell.execute_reply": "2023-09-10T03:44:22.456689Z"}}, "outputs": [{"ename": "NameError", "evalue": "name 'rnn' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[4], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Loss function and optimizer\u001b[39;00m\n\u001b[1;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mNLLLoss()\n\u001b[0;32m---> 13\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mrnn\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0005\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Function to perform one training step\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(input_line_tensor, target_line_tensor):\n", "\u001b[0;31mNameError\u001b[0m: name 'rnn' is not defined"]}], "source": ["def random_training_set():    \n", "    start_index = random.randint(0, len(lorem_ipsum) - 2)\n", "    end_index = random.randint(start_index, len(lorem_ipsum) - 1)\n", "    line = lorem_ipsum[start_index:end_index]\n", "    input_line_tensor = line_to_tensor(line)\n", "    target_line_tensor = line_to_tensor(lorem_ipsum[start_index+1:end_index+1])\n", "    return input_line_tensor, target_line_tensor\n", "\n", "\n", "# Function to perform one training step\n", "\n", "def train(input_line_tensor, target_line_tensor):\n", "    target_line_tensor.unsqueeze_(-1)\n", "    hidden = rnn.initHidden()\n", "    rnn.zero_grad()\n", "    loss = 0\n", "    for i in range(input_line_tensor.size(0)):\n", "        output, hidden = rnn(input_line_tensor[i], hidden)\n", "        l = criterion(output, target_line_tensor[i])\n", "        loss += l\n", "    loss.backward()\n", "    optimizer.step()\n", "    return output, loss.item() / input_line_tensor.size(0)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def generate(decoder, prime_str='A', predict_len=100, temperature=0.8):\n", "    hidden = decoder.initHidden()\n", "    prime_input = line_to_tensor(prime_str)\n", "    predicted = prime_str\n", "\n", "    for p in range(len(prime_str) - 1):\n", "        _, hidden = decoder(prime_input[p], hidden)\n", "    inp = prime_input[-1]\n", "    \n", "    for p in range(predict_len):\n", "        output, hidden = decoder(inp, hidden)\n", "\n", "        # Sample from the network as a multinomial distribution\n", "        output_dist = output.data.view(-1).div(temperature).exp()\n", "        top_i = torch.multinomial(output_dist, 1)[0]\n", "\n", "        # Add predicted character to string and use as next input\n", "        predicted_char = all_characters[top_i]\n", "        predicted += predicted_char\n", "        inp = char_to_tensor(predicted_char)\n", "\n", "    return predicted\n", "\n", "# Training process\n", "n_epochs = 5000\n", "print_every = 500\n", "plot_every = 10\n", "hidden_size = 100\n", "n_layers = 1\n", "lr = 0.005\n", "\n", "rnn = RNN(n_characters, hidden_size, n_characters)\n", "start = time.time()\n", "all_losses = []\n", "current_loss = 0\n", "\n", "for epoch in range(1, n_epochs + 1):\n", "    output, loss = train(*random_training_set())\n", "    current_loss += loss\n", "\n", "    if epoch % print_every == 0:\n", "        print(f'time: {time.time() - start} | epoch: {epoch} ({epoch / n_epochs * 100}%) | loss: {loss}')\n", "        print(generate(rnn, 'Li', 200), '\\n')\n", "\n", "    if epoch % plot_every == 0:\n", "        all_losses.append(current_loss / plot_every)\n", "        current_loss = 0\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["plt.figure()\n", "plt.plot(all_losses)\n"]}], "metadata": {"kernelspec": {"display_name": "base", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.12"}}, "nbformat": 4, "nbformat_minor": 2}